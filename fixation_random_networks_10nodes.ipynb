{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.functions import *\n",
    "\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms import bipartite\n",
    "import sys\n",
    "import contextlib\n",
    "import itertools\n",
    "from math import comb\n",
    "from numpy import linalg as LA\n",
    "import math\n",
    "from numpy.linalg import matrix_power\n",
    "import matplotlib.pyplot as plt\n",
    "from math import factorial as f\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import time\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "\n",
    "def theoretic_fixation_moran(nodes,fitness):\n",
    "    if fitness==1:\n",
    "        return 1/(nodes)\n",
    "    else:\n",
    "        k=(1-1/fitness)/(1-1/(pow(fitness,nodes)))\n",
    "        return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:00:00.382121\n"
     ]
    }
   ],
   "source": [
    "    ### Generate the 100 connected random graphs\n",
    "    ### Each of 100 graph will have 100 random weighted versions\n",
    "    start_time = datetime.now()\n",
    "    random_graph_list=[]\n",
    "    c=0\n",
    "    while len(random_graph_list)<100:\n",
    "        c=c+1\n",
    "        p=(c%10)/10\n",
    "        ##we are varying p as we go along\n",
    "    \n",
    "        G=nx.fast_gnp_random_graph(10, p, seed=None, directed=False)\n",
    "        if nx.is_connected(G) == False :\n",
    "            continue\n",
    "        else:\n",
    "            random_graph_list.append(G)\n",
    "        \n",
    "\n",
    "        \n",
    "    ### Generating the weighted versions:\n",
    "    ### Each row has 101 columns, 1 for the original network, 100 for the weighted networks.\n",
    "    ### random_graph_data will store the fixation probability of each of the networks\n",
    "    random_graph_data= np.zeros((100,101), dtype=object)\n",
    "    random_graph_collection =  np.zeros((100,101), dtype=object)\n",
    "\n",
    "    for i in range(len(random_graph_list)):#for each network\n",
    "    \n",
    "        random_graph_collection[i,0]=random_graph_list[i]\n",
    "        #random_graph_data[i,0]=[matrix_solver(T_weightMat(random_graph_collection[i,0],k/10))-theoretic_fixation_moran(10,k/10) for  k in range(1,20)]\n",
    "        for j in range(1,101): #for each weighted analogue of a network\n",
    "            G=random_graph_collection[i,0]\n",
    "            for u,v in G.edges():\n",
    "                G[u][v]['weight']=rnd.random()\n",
    "\n",
    "            random_graph_collection[i,j]=G\n",
    "            \n",
    "    end_time = datetime.now()\n",
    "    print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_10_nodes_weighted(index,weight_index):    \n",
    "    return [matrix_solver(T_weightMat(random_graph_collection[index,weight_index],t/10))-theoretic_fixation_moran(10,t/10) for  t in range(1,20)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-35-7bf25d82f5e0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-7bf25d82f5e0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    nx.is_regular(random_graph_list\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "np.save('random_graph_collection.npy', random_graph_collection)\n",
    "np.save('random_graph_data.npy', random_graph_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting computations on 56 cores\n",
      "elapsed time: 4829.829804899171\n",
      "starting computations on 56 cores\n",
      "elapsed time: 4814.532375191804\n",
      "starting computations on 56 cores\n",
      "elapsed time: 4797.140383997001\n",
      "starting computations on 56 cores\n",
      "elapsed time: 5072.240246076835\n",
      "starting computations on 56 cores\n",
      "elapsed time: 4857.937398198992\n",
      "starting computations on 56 cores\n",
      "elapsed time: 4801.409766741097\n",
      "starting computations on 56 cores\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from timeit import default_timer as timer\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "\n",
    "def main(j):\n",
    "    \n",
    "    start = timer()\n",
    "    c=[]\n",
    "    arg=[]\n",
    "\n",
    "    print(f'starting computations on {cpu_count()} cores')\n",
    "    \n",
    "    for l in range(101):\n",
    "        arg.append((j,l))\n",
    "\n",
    "\n",
    "    with Pool() as pool:\n",
    "        c.append(pool.starmap(random_10_nodes_weighted, arg))\n",
    "        \n",
    "\n",
    "    end = timer()\n",
    "    print(f'elapsed time: {end - start}')\n",
    "    return c\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    random_graph_data =  np.zeros((100,101), dtype=object)\n",
    "    c=[]\n",
    "    for k in range(100):\n",
    "        random_graph_data[k]=main(k)\n",
    "        np.save('random_graph_data.npy', random_graph_data )\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-6.26488796415371e-11,\n",
       " -2.2624553628106084e-08,\n",
       " -5.980428212773214e-07,\n",
       " -5.263875160013991e-06,\n",
       " -2.4395619257227934e-05,\n",
       " -7.153911247797639e-05,\n",
       " -0.0001426408184045068,\n",
       " -0.00019354601722283704,\n",
       " -0.00015711977602071714,\n",
       " 1.3877787807814457e-17,\n",
       " 0.00024867903118278023,\n",
       " 0.0005272164069345664,\n",
       " 0.0007833091824055449,\n",
       " 0.0009901994503546674,\n",
       " 0.001141950971501382,\n",
       " 0.0012437389750514227,\n",
       " 0.0013047127830048688,\n",
       " 0.0013342654939783594,\n",
       " 0.0013405377609437275]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_graph_data[22][13][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " random_graph_data= np.load('random_graph_data.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_graph_data[49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##classifying \n",
    "\n",
    "classifier = np.zeros((100, 101), dtype=object)\n",
    "\n",
    "check=[]\n",
    "\n",
    "for i in range(50):\n",
    "    for j in range(1,100):\n",
    "        for k in range(3,19):\n",
    "            if k==9:\n",
    "                continue\n",
    "            check.append(np.sign(random_graph_data[i][j][1][k]))\n",
    "        #print(check)\n",
    "        #print()\n",
    "        #print(i,j,k)\n",
    "        if check==[1,1,1,1,1,1,-1,-1,-1,-1,-1,-1,-1,-1,-1]:\n",
    "            #suppressor\n",
    "            classifier[i,j]= \"Suppressor\"\n",
    "        elif check==[-1,-1,-1,-1,-1,-1,1,1,1,1,1,1,1,1,1]:\n",
    "            #amplifier\n",
    "            classifier[i,j]= \"Amplifier\"\n",
    "        elif check==[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]:\n",
    "            #isothermal\n",
    "            classifier[i,j]= \"Isothermal\"\n",
    "        else:\n",
    "            #neither\n",
    "            classifier[i,j]= \"Neither\"\n",
    "        check=[]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2970 1287 793 0\n"
     ]
    }
   ],
   "source": [
    "###list of suppressors and 'neither' networks\n",
    "amp=0\n",
    "sup=0\n",
    "neither=0\n",
    "iso=0\n",
    "\n",
    "sup_list=[]\n",
    "neither_list=[]\n",
    "iso_list=[]\n",
    "\n",
    "for i in range(50):\n",
    "    for j in range(101):\n",
    "        if classifier[i,j]== \"Suppressor\":\n",
    "            sup+=1\n",
    "            sup_list.append([i,j])\n",
    "        elif classifier[i,j]== \"Amplifier\":\n",
    "            amp+=1\n",
    "        elif classifier[i,j]== \"Isothermal\":\n",
    "            iso+=1\n",
    "            iso_list.append([i,j])\n",
    "        else:\n",
    "            neither+=1\n",
    "            neither_list.append([i,j])\n",
    "            \n",
    "            \n",
    "print(amp, sup, neither,iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata=[]\n",
    "s=0\n",
    "a=0\n",
    "n=0\n",
    "for i in range(112):\n",
    "    #each row will contain 4 things, graph enumeration, number of amps, sups, neither \n",
    "    a= list(classifier[i]).count('Amplifier')#count number of occurrences of amplifier in classifier\n",
    "    s= list(classifier[i]).count('Suppressor')\n",
    "    n= 10-a-s\n",
    "    dfdata.append([i,a,s,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the dataframe\n",
    "df.to_pickle('weighted_networks.pkl')  \n",
    "df = pd.read_pickle('weighted_networks.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3e4443acfcdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Weighted_Networks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type[102]=\"Suprressor\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
